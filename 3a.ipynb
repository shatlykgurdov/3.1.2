{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyki0ytRV41bosBfrJK+RF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shatlykgurdov/3.1.2/blob/main/3a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRlKsI2GzSA3"
      },
      "outputs": [],
      "source": [
        "# Problem 3a – Model Selection for Y ~ Z1, Z2, Z3, Z4, Z5\n",
        "# Group 12282 (even) → FE-GWP1_model_selection_2.csv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# =========================\n",
        "# 1. Load the dataset\n",
        "# =========================\n",
        "df = pd.read_csv(\"FE-GWP1_model_selection_2.csv\")\n",
        "\n",
        "# Clean column names: remove leading/trailing spaces\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "print(\"First 5 rows of dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in dataset:\", df.columns.tolist())\n",
        "\n",
        "# Now columns should be: 'Y', 'Z1', 'Z2', 'Z3', 'Z4', 'Z5'\n",
        "y = df[\"Y\"]\n",
        "X_all = df[[\"Z1\", \"Z2\", \"Z3\", \"Z4\", \"Z5\"]]\n",
        "candidate_predictors = list(X_all.columns)\n",
        "\n",
        "# Helper function to fit OLS model with given predictors\n",
        "def fit_model(predictors):\n",
        "    X = sm.add_constant(X_all[list(predictors)])\n",
        "    model = sm.OLS(y, X).fit()\n",
        "    return model\n",
        "\n",
        "# =========================\n",
        "# 2. Approach 1: All-subsets model selection\n",
        "#    (Adjusted R², AIC, BIC)\n",
        "# =========================\n",
        "results = []\n",
        "\n",
        "for k in range(1, len(candidate_predictors) + 1):\n",
        "    for subset in itertools.combinations(candidate_predictors, k):\n",
        "        model = fit_model(subset)\n",
        "        results.append({\n",
        "            \"predictors\": subset,\n",
        "            \"adj_R2\": model.rsquared_adj,\n",
        "            \"AIC\": model.aic,\n",
        "            \"BIC\": model.bic\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Top models by each criterion\n",
        "best_by_adjR2 = results_df.sort_values(\"adj_R2\", ascending=False).head(5)\n",
        "best_by_AIC   = results_df.sort_values(\"AIC\", ascending=True).head(5)\n",
        "best_by_BIC   = results_df.sort_values(\"BIC\", ascending=True).head(5)\n",
        "\n",
        "print(\"\\n=== Top 5 models by Adjusted R² ===\")\n",
        "print(best_by_adjR2)\n",
        "\n",
        "print(\"\\n=== Top 5 models by AIC ===\")\n",
        "print(best_by_AIC)\n",
        "\n",
        "print(\"\\n=== Top 5 models by BIC ===\")\n",
        "print(best_by_BIC)\n",
        "\n",
        "# Choose one \"best\" model by BIC\n",
        "best_model_row = best_by_BIC.iloc[0]\n",
        "best_predictors = list(best_model_row[\"predictors\"])\n",
        "print(\"\\n>>> Chosen best model by BIC has predictors:\", best_predictors)\n",
        "\n",
        "best_model = fit_model(best_predictors)\n",
        "print(\"\\n=== Summary of best model by BIC ===\")\n",
        "print(best_model.summary())\n",
        "\n",
        "# =========================\n",
        "# 3. Approach 2: Forward stepwise selection (AIC)\n",
        "# =========================\n",
        "def forward_stepwise_selection(X, y, verbose=True):\n",
        "    remaining = list(X.columns)\n",
        "    selected = []\n",
        "    current_score = np.inf\n",
        "    best_new_score = np.inf\n",
        "\n",
        "    while remaining:\n",
        "        scores_with_candidates = []\n",
        "\n",
        "        for candidate in remaining:\n",
        "            predictors = selected + [candidate]\n",
        "            X_candidate = sm.add_constant(X[predictors])\n",
        "            model = sm.OLS(y, X_candidate).fit()\n",
        "            scores_with_candidates.append((model.aic, candidate))\n",
        "\n",
        "        # Pick candidate with lowest AIC\n",
        "        scores_with_candidates.sort()\n",
        "        best_new_score, best_candidate = scores_with_candidates[0]\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Trying to add {best_candidate}: AIC = {best_new_score:.3f}\")\n",
        "\n",
        "        if best_new_score < current_score - 1e-6:  # improvement\n",
        "            remaining.remove(best_candidate)\n",
        "            selected.append(best_candidate)\n",
        "            current_score = best_new_score\n",
        "            if verbose:\n",
        "                print(f\"  -> Added {best_candidate}, new AIC = {current_score:.3f}\")\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"No further AIC improvement. Stopping forward selection.\")\n",
        "            break\n",
        "\n",
        "    return selected, current_score\n",
        "\n",
        "print(\"\\n=== Forward Stepwise Selection (AIC) ===\")\n",
        "forward_predictors, forward_aic = forward_stepwise_selection(X_all, y, verbose=True)\n",
        "print(\"\\n>>> Forward stepwise selected predictors:\", forward_predictors)\n",
        "print(\"Final AIC from forward selection:\", forward_aic)\n",
        "\n",
        "X_forward = sm.add_constant(X_all[forward_predictors])\n",
        "forward_model = sm.OLS(y, X_forward).fit()\n",
        "print(\"\\n=== Summary of forward stepwise model ===\")\n",
        "print(forward_model.summary())\n",
        "\n",
        "# =========================\n",
        "# 4. Approach 3: Backward elimination (BIC)\n",
        "# =========================\n",
        "def backward_elimination(X, y, verbose=True, criterion=\"BIC\"):\n",
        "    predictors = list(X.columns)\n",
        "\n",
        "    # Start with full model\n",
        "    X_full = sm.add_constant(X[predictors])\n",
        "    model_full = sm.OLS(y, X_full).fit()\n",
        "    if criterion == \"AIC\":\n",
        "        best_score = model_full.aic\n",
        "    elif criterion == \"BIC\":\n",
        "        best_score = model_full.bic\n",
        "    else:\n",
        "        raise ValueError(\"criterion must be 'AIC' or 'BIC'\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nStart backward elimination with full model {predictors}, {criterion} = {best_score:.3f}\")\n",
        "\n",
        "    improved = True\n",
        "    while improved and len(predictors) > 1:\n",
        "        scores_with_candidates = []\n",
        "\n",
        "        for candidate in predictors:\n",
        "            trial_predictors = [p for p in predictors if p != candidate]\n",
        "            X_trial = sm.add_constant(X[trial_predictors])\n",
        "            trial_model = sm.OLS(y, X_trial).fit()\n",
        "            score = trial_model.aic if criterion == \"AIC\" else trial_model.bic\n",
        "            scores_with_candidates.append((score, candidate, trial_predictors))\n",
        "\n",
        "        scores_with_candidates.sort()\n",
        "        best_new_score, worst_predictor, best_predictor_set = scores_with_candidates[0]\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Trying to remove {worst_predictor}: {criterion} = {best_new_score:.3f}\")\n",
        "\n",
        "        if best_new_score < best_score - 1e-6:\n",
        "            predictors = best_predictor_set\n",
        "            best_score = best_new_score\n",
        "            if verbose:\n",
        "                print(f\"  -> Removed {worst_predictor}, new {criterion} = {best_score:.3f}\")\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"No further improvement. Stopping backward elimination.\")\n",
        "            improved = False\n",
        "\n",
        "    final_X = sm.add_constant(X[predictors])\n",
        "    final_model = sm.OLS(y, final_X).fit()\n",
        "    return predictors, best_score, final_model\n",
        "\n",
        "print(\"\\n=== Backward Elimination (BIC) ===\")\n",
        "backward_predictors, backward_score, backward_model = backward_elimination(X_all, y, verbose=True, criterion=\"BIC\")\n",
        "print(\"\\n>>> Backward elimination (BIC) selected predictors:\", backward_predictors)\n",
        "print(\"Final BIC from backward elimination:\", backward_score)\n",
        "print(\"\\n=== Summary of backward elimination model ===\")\n",
        "print(backward_model.summary())\n",
        "\n",
        "# =========================\n",
        "# 5. Final comparison info\n",
        "# =========================\n",
        "print(\"\\n================ FINAL SUMMARY ================\")\n",
        "print(\"Best model by BIC (all-subsets) predictors:\", best_predictors)\n",
        "print(\"Forward stepwise selected predictors:\", forward_predictors)\n",
        "print(\"Backward elimination (BIC) selected predictors:\", backward_predictors)\n",
        "print(\"Use these results to justify your final chosen model in the report.\")\n"
      ]
    }
  ]
}